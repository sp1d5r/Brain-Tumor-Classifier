{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "is_executing": false
    }
   },
   "source": [
    "# Brain Tumor Project\n",
    "\n",
    "This is the notebook where the project gets taken place"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Checking and Preprocessing "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import pandas as pd \n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "import os\n",
    "\n",
    "DATA_CHECKING = False     # Change this to True to test datasets\n",
    "\n",
    "\n",
    "# Important info\n",
    "# 1. Categories\n",
    "CATEGORIES = [\"glioma_tumor\",\"meningioma_tumor\",\"no_tumor\",\"pituitary_tumor\"]\n",
    "\n",
    "# 2. Dataset directory\n",
    "DIR_PATH = os.getcwd() + '/brain_tumor_dataset'\n",
    "\n",
    "# 3. Training and Testing Directories \n",
    "TRAINING_PATH = DIR_PATH + \"/Training/\"\n",
    "TESTING_PATH = DIR_PATH + \"/Testing/\"\n",
    "\n",
    "# 3. Resizing the training data\n",
    "IMG_SIZE = 150\n",
    "\n",
    "\n",
    "# Check the Data:\n",
    "if (DATA_CHECKING):\n",
    "    # -- This will traverse the directory and print all the \n",
    "    # relevant filenames. Just check that all four \n",
    "    for dirname, _, filenames in os.walk(DIR_PATH):\n",
    "        print(dirname)\n",
    "        for filename in filenames:\n",
    "            print(os.path.join(dirname, filename))\n",
    "\n",
    "    # This will print all the images one after another \n",
    "    for category in CATEGORIES:\n",
    "        path = os.path.join(TRAINING_PATH,category)\n",
    "        for img in os.listdir(path):\n",
    "            print(os.path.join(path,img))\n",
    "            img_array = cv2.imread(os.path.join(path,img))\n",
    "            plt.imshow(img_array)\n",
    "            plt.show()\n",
    "            plt.axis(\"off\")\n",
    "        break\n",
    "        \n",
    "    IMG_SIZE = 150\n",
    "    new_array = cv2.resize(img_array,(IMG_SIZE,IMG_SIZE))    \n",
    "    plt.imshow(new_array,cmap = \"gray\")\n",
    "    plt.axis(\"off\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_data = []\n",
    "\n",
    "def populate_training_data():\n",
    "    for category in CATEGORIES:\n",
    "        new_path = os.path.join(TRAINING_PATH, category)\n",
    "        category_index = CATEGORIES.index(category)\n",
    "        \n",
    "        for img in os.listdir(new_path):\n",
    "            try:\n",
    "                img_array = cv2.imread(os.path.join(new_path,img),cv2.IMREAD_GRAYSCALE)\n",
    "                new_array = cv2.resize(img_array,(IMG_SIZE,IMG_SIZE)) \n",
    "                training_data.append([new_array,category_index])\n",
    "            except Exception as e:\n",
    "                print(\"failed\", e)\n",
    "                pass\n",
    "\n",
    "# This takes the files in the training path and places them in this order [image, int] \n",
    "# where image = the image data, and int is the category it's in.\n",
    "# [glioma_tumor = 0, meningioma_tumor = 1, no_tumor = 2, pituitary_tumor = 3]\n",
    "populate_training_data()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = []\n",
    "y = []\n",
    "\n",
    "for features,label in training_data:\n",
    "    X.append(features)\n",
    "    y.append(label)\n",
    "    \n",
    "# this is used to reshape and flatten the data.\n",
    "X = np.array(X).reshape(-1,IMG_SIZE,IMG_SIZE)\n",
    "X = X/255.0 \n",
    "X = X.reshape(-1,150,150,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.utils.np_utils import to_categorical # convert to one-hot-encoding\n",
    "y = to_categorical(y, num_classes = 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_train shape (2296, 150, 150, 1)\n",
      "x_test shape (574, 150, 150, 1)\n",
      "y_train shape (2296, 4)\n",
      "y_test shape (574, 4)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_val, Y_train, Y_val = train_test_split(X, y, test_size = 0.2, random_state=42)\n",
    "print(\"x_train shape\",X_train.shape)\n",
    "print(\"x_test shape\",X_val.shape)\n",
    "print(\"y_train shape\",Y_train.shape)\n",
    "print(\"y_test shape\",Y_val.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "import itertools\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Flatten, Conv2D, MaxPooling2D, Activation\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convolutional Neural Network \n",
    "You take an image, then convert the image into pixel data, then convert it into a grid or such. Now you have a convlutional window. i.e. a 3x3 window. Then this simplifies it down into a single thing. Then it turns these simplified things down. \n",
    "\n",
    "say for example, the we used convolution and max pooling, you look at your window and then take the values from it. From these values you take the maximum value. which gives you the next feature layer. Makes sense right?\n",
    "\n",
    "Basically what's happening is it's slowly extracting values. The lower layers extract edges, then lines, then larger and larger stuff. Does that make sense? Okay. Moving on."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "58/58 [==============================] - 36s 599ms/step - loss: 0.9557 - accuracy: 0.5858 - val_loss: 0.6231 - val_accuracy: 0.7544\n",
      "Epoch 2/5\n",
      "58/58 [==============================] - 35s 611ms/step - loss: 0.5196 - accuracy: 0.7979 - val_loss: 0.4790 - val_accuracy: 0.7892\n",
      "Epoch 3/5\n",
      "58/58 [==============================] - 33s 572ms/step - loss: 0.3134 - accuracy: 0.8794 - val_loss: 0.3965 - val_accuracy: 0.8397\n",
      "Epoch 4/5\n",
      "58/58 [==============================] - 34s 587ms/step - loss: 0.1901 - accuracy: 0.9303 - val_loss: 0.4452 - val_accuracy: 0.8397\n",
      "Epoch 5/5\n",
      "58/58 [==============================] - 33s 577ms/step - loss: 0.1204 - accuracy: 0.9608 - val_loss: 0.3579 - val_accuracy: 0.8746\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fa4f3f4fa58>"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Using a Sequential Model \n",
    "model = Sequential()\n",
    "\n",
    "# Applying a convlutional layer\n",
    "model.add(Conv2D(64, (5,5), input_shape = (150,150,1)))    # could be X.shape[1:]\n",
    "model.add(Activation('relu')) # you could pass activation/pooling in whatever order\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "\n",
    "model.add(Conv2D(64, (3,3), input_shape = (150,150,1)))    # could be X.shape[1:]\n",
    "model.add(Activation('relu')) # you could pass activation/pooling in whatever order\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    " \n",
    "model.add(Flatten())\n",
    "model.add(Dense(64, activation = \"relu\"))\n",
    "model.add(Dense(4, activation = \"softmax\"))\n",
    "\n",
    "\n",
    "model.compile(optimizer = 'adam' , loss = \"categorical_crossentropy\", metrics=[\"accuracy\"])\n",
    "epochs = 5 \n",
    "batch_size = 40\n",
    "\n",
    "model.fit(X_train, Y_train, batch_size=batch_size, epochs = epochs, validation_data = (X_val,Y_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = \"finalized_brain_tumor_model.h5\"\n",
    "model.save(filename)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "metadata": {
     "collapsed": false
    },
    "source": []
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
